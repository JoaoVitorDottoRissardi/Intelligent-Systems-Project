#Original
solver = ["sgd"]
activation = ["relu", "logistic", "tanh"]
momentum = [0.9]
tol = [1e-3, 1e-4, 1e-5, 1e-6, 1e-7]
learning_rate = ['constant', 'adaptive', 'invscaling']
learning_rate_init = [1e-3, 5e-4, 1e-4]
alpha = [1e-4]
# random_state = [5, 10, 15, 20, 25]
max_iter = [300000]
n_iter_no_change = [20, 200, 2000]
verbose = [False]
early_stopping = [True, False]
hidden_layer_sizes = [(10, 10, 10), (50, 40, 20, 10), (10, 5, 5), (8, 9, 10), (20, 25, 15), (25, 30, 5), (15, 30), (15, 15, 15, 15)]

#
nn = MLPRegressor(
    activation='relu',
    solver='sgd',
    hidden_layer_sizes=(500, 100, 10),
    alpha=0.0001,
    verbose=True,
    early_stopping=True,
    learning_rate='constant',
    learning_rate_init=0.0005,
    max_iter=30000,
    tol=1e-7,
    n_iter_no_change=10000
)


#resultado 1

#800 dados Nossos
RMSE:  1.9121804054919211
Score:  0.9858869959376447
RMSE:  1.9121804054919211
Score:  0.9858869959376447
Params:  {'activation': 'relu', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (10, 10, 10), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 1000, 'momentum': 0.9, 'n_iter_no_change': 100, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': None, 'shuffle': True, 'solver': 'sgd', 'tol': 1e-05, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}

=== Treino ===
R_squared value:  0.9692656335726161
RMSE:  2.9563155466118687
=== Validação ===
R_squared value:  0.9857140717255487
RMSE:  1.923859547641651
=== Dados do Thiago ===
R_squared value:  0.7878553541221479
RMSE:  7.8345235044562145


#resultado 2

nn = MLPRegressor(
    activation='relu',
    solver='sgd',
    hidden_layer_sizes=(11, 10, 9),
    alpha=0.0001,
    verbose=True,
    early_stopping=False,
    learning_rate='constant',
    learning_rate_init=0.001,
    max_iter=10000,
    tol=1e-5,
    n_iter_no_change=100
)

#Modelo1
=== Treino ===
R_squared value:  0.9717826637915092
RMSE:  2.8326744232643177
=== Validação ===
R_squared value:  0.9856892747244056
RMSE:  1.9255285068743144
=== Dados do Thiago ===
R_squared value:  0.7828527214254865
RMSE:  7.926359128711985

#Modelo2

RMSE:  0.8560644336624977
Score:  0.997171379740825
RMSE:  0.8560644336624977
Score:  0.997171379740825
Params:  {'activation': 'tanh', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (17, 17, 17), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0004, 'max_fun': 15000, 'max_iter': 5000, 'momentum': 0.9, 'n_iter_no_change': 700, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': None, 'shuffle': True, 'solver': 'sgd', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}

=== Treino ===
R_squared value:  0.9795385100416062
RMSE:  2.41216650307378
=== Validação ===
R_squared value:  0.9970211164508138
RMSE:  0.8785083492413706
=== Dados do Thiago ===
R_squared value:  0.78943960417116
RMSE:  7.805215427033419

#Modelo3

RMSE:  0.5722243039784427
Score:  0.9987361534753842
RMSE:  0.5722243039784427
Score:  0.9987361534753842
Params:  {'activation': 'tanh', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (17, 17, 17), 'learning_rate': 'constant', 'learning_rate_init': 0.0004, 'max_fun': 15000, 'max_iter': 10000, 'momentum': 0.9, 'n_iter_no_change': 600, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': None, 'shuffle': True, 'solver': 'sgd', 'tol': 1e-05, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}
=== Treino ===
R_squared value:  0.9807035374086506
RMSE:  2.3424887065781537
=== Validação ===
R_squared value:  0.9984774677077007
RMSE:  0.6280618102385114
=== Dados do Thiago ===
R_squared value:  0.7735706004642157
RMSE:  8.093995479762187

#Modelo4

nn = MLPRegressor(
    activation='relu',
    solver='sgd',
    hidden_layer_sizes=(20, 20, 20),
    alpha=0.0001,
    verbose=False,
    early_stopping=False,
    learning_rate='adaptive',
    learning_rate_init=0.0005,
    max_iter=50000,
    tol=1e-5,
    n_iter_no_change=500
)

=== Treino ===
R_squared value:  0.9763308402554194
RMSE:  2.5943590172039577
=== Validação ===
R_squared value:  0.9992558476606175
RMSE:  0.43908647103414056
=== Dados do Thiago ===
R_squared value:  0.7705120203460072
RMSE:  8.148478450880809

#Modelo5

nn = MLPRegressor(
    activation='relu',
    solver='sgd',
    hidden_layer_sizes=(20, 20, 20),
    alpha=0.0001,
    verbose=False,
    early_stopping=False,
    learning_rate='constant',
    learning_rate_init=0.0005,
    max_iter=30000,
    tol=1e-5,
    n_iter_no_change=1000
)

=== Treino ===
R_squared value:  0.9750431323616237
RMSE:  2.6639967623955005
=== Validação ===
R_squared value:  0.9903128552984095
RMSE:  1.5842255887587442
=== Dados do Thiago ===
R_squared value:  0.7918773667008141
RMSE:  7.759901457203281

#Modelo6

RMSE:  0.9312681416105641
Score:  0.9966525720991658
RMSE:  0.9312681416105641
Score:  0.9966525720991658
Params:  {'activation': 'tanh', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (20, 20, 20), 'learning_rate': 'constant', 'learning_rate_init': 7e-05, 'max_fun': 15000, 'max_iter': 20000, 'momentum': 0.9, 'n_iter_no_change': 1000, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': None, 'shuffle': True, 'solver': 'sgd', 'tol': 1e-05, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}
